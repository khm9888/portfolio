{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sum(data))\n",
    "print(torch.mean(data))\n",
    "print(torch.var(data))\n",
    "print(torch.std(data))\n",
    "print()\n",
    "#scalar value에 대해서 tensor 속의 값만 추출함\n",
    "print(torch.sum(data).item())\n",
    "print(torch.mean(data).item())\n",
    "print(torch.var(data).item())\n",
    "print(torch.std(data).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pytorch 조건문\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.where(data>0, torch.ones(data.shape),torch.zeros(data.shape)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*numpy 호환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 5행 1열 : tensor([1., 1., 1., 1., 1.])\n",
      "torch->numpy 변환 5행 1열 : [1. 1. 1. 1. 1.]\n",
      "numpy->torch 변환 5행 1열 : tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(f\"torch 5행 1열 : {a}\")\n",
    "b = a.numpy()\n",
    "print(f\"torch->numpy 변환 5행 1열 : {b}\")\n",
    "c = torch.from_numpy(b)\n",
    "print(f\"numpy->torch 변환 5행 1열 : {c}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gpu의 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # 가능한지\n",
    "print(torch.cuda.device_count()) # 몇개가 있는지\n",
    "# print(torch.cuda.current_device()) # 추후 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\",device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# gpu 자원이 사용가능하다면\n",
    "x = torch.tensor([1,1]).to(device)# 사용할 자원에 맞춰서\n",
    "print(x)\n",
    "#추후 활용\n",
    "# https://m.blog.naver.com/ptm0228/222048480521\n",
    "# 직접적으로 장치를 선택하여\n",
    "# x.cuda()\n",
    "# x.cpu()\n",
    "# 로 지정도 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,1]).cuda()\n",
    "y = torch.tensor([1,1]).cpu()\n",
    "print(x+y)#동일한 위치가 아니기 때문에 에러가 남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True)\n",
      "tensor([1.], requires_grad=True)\n",
      "tensor([3.], grad_fn=<AddBackward0>)\n",
      "tensor([2.], grad_fn=<AddBackward0>)\n",
      "tensor([5.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2.], requires_grad=True)\n",
    "b = torch.tensor([1.], requires_grad=True)\n",
    "c = a+b\n",
    "d = b+1\n",
    "e = c+d\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.data)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient가 계산되려면\n",
    "e.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(c.grad)\n",
    "print(d.grad)\n",
    "print(e.grad)\n",
    "# tensor([1.])\n",
    "# tensor([2.])\n",
    "# None\n",
    "# None\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([2.])\n",
      "tensor([2.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2.],requires_grad=True)\n",
    "b = torch.tensor([1.],requires_grad=True)\n",
    "c = a+b\n",
    "d = c+1\n",
    "e = c+d\n",
    "\n",
    "c.retain_grad()\n",
    "d.retain_grad()\n",
    "e.retain_grad()\n",
    "\n",
    "e.backward(retain_graph=True)\n",
    "\n",
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(c.grad)\n",
    "print(d.grad)\n",
    "print(e.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# gradient 값은 초기화를 시키지 않으면 계속 누적하여 곱셈이 이루어지기 때문에\n",
    "# backward를 한 이후에 바로 grad_zero_() method를 진행해야함\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "c.grad.zero_()\n",
    "d.grad.zero_()\n",
    "e.grad.zero_()\n",
    "\n",
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(c.grad)\n",
    "print(d.grad)\n",
    "print(e.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 그럴 일은 거의 없지만 requires_grad 를 false를 하여 grad 계산을 멈춤\n",
    "a.requires_grad = False\n",
    "\n",
    "a = a.detach()\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망 형성\n",
    "# 보통 클래스로 만듬\n",
    "\n",
    "class Net(nn.Module): ## nn.Module  을 상속해야함\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__() #상속을 위한 스텝\n",
    "        self.fc1 = nn.Linear(in_features=100,out_features=100)\n",
    "        self.fc1_act = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=100,out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc1_act(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc1_act): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Parameter containing:\n",
      "tensor([[-0.0178, -0.0774,  0.0715,  ...,  0.0563, -0.0517,  0.0817],\n",
      "        [-0.0192,  0.0492,  0.0698,  ..., -0.0926,  0.0926, -0.0624],\n",
      "        [-0.0692, -0.0939, -0.0616,  ...,  0.0123, -0.0827, -0.0470],\n",
      "        ...,\n",
      "        [ 0.0741,  0.0673,  0.0804,  ..., -0.0495, -0.0031, -0.0048],\n",
      "        [-0.0955,  0.0500, -0.0799,  ..., -0.0822,  0.0782,  0.0008],\n",
      "        [-0.0539, -0.0503, -0.0601,  ..., -0.0452,  0.0069, -0.0424]],\n",
      "       requires_grad=True)\n",
      "torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "# print(params)\n",
    "print(len(params)) #레이어 개수(현재 2개)*(weight 관련 param + bias 관련 param = 2개)\n",
    "print(params[0])\n",
    "print(params[0].size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. net instance에서 direct하게 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1844, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 배치 사이즈 # 한 번에 계산하려는 데이터의 사이즈\n",
    "batch_size = 10\n",
    "input = torch.randn(batch_size,100)\n",
    "output = net(input)\n",
    "\n",
    "target = torch.randn(batch_size,10)\n",
    "criterion = nn.MSELoss() #mean squared loss\n",
    "\n",
    "loss = criterion(output,target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias.grad before backward\n",
      "None\n",
      "fc1.bias.grad before backward\n",
      "tensor([ 4.2509e-03, -8.8796e-04,  8.2000e-03,  7.7617e-03, -8.8292e-03,\n",
      "         2.9105e-02,  7.3921e-03,  7.9663e-03,  7.1408e-03,  8.1933e-03,\n",
      "         2.6814e-03, -1.4268e-03, -1.4156e-02,  2.6951e-03, -2.4230e-03,\n",
      "        -3.2404e-04,  6.3983e-03,  1.3524e-02, -1.1312e-02,  8.8882e-03,\n",
      "         3.4021e-03, -5.2625e-03,  9.2296e-03, -1.7122e-02,  2.1895e-02,\n",
      "         1.3825e-02,  6.9349e-03, -1.7986e-02, -8.4713e-03, -9.9984e-03,\n",
      "         9.2334e-04, -5.1077e-03,  1.8640e-02, -7.0314e-03, -1.6431e-02,\n",
      "        -5.2081e-03, -7.1744e-03,  1.8677e-03,  1.4005e-02, -2.0012e-02,\n",
      "        -1.1166e-02,  8.7468e-05,  9.2844e-03, -7.6586e-03, -7.1273e-03,\n",
      "        -1.5413e-03, -4.4460e-03, -1.0996e-02, -1.3622e-02, -2.9072e-03,\n",
      "         1.6537e-03, -1.5929e-02, -6.1317e-03, -5.1228e-03, -5.7224e-04,\n",
      "         6.0707e-03,  1.8488e-02,  1.5422e-02,  6.9745e-03,  1.2333e-02,\n",
      "         5.1620e-03, -6.0328e-03, -1.7460e-03,  7.6466e-03, -9.9645e-03,\n",
      "        -3.9167e-03,  2.8205e-02, -9.1661e-03,  1.7541e-02,  2.7942e-03,\n",
      "        -3.8904e-03, -1.7707e-02,  9.5294e-03, -1.7389e-02, -6.4709e-03,\n",
      "         2.3453e-03,  2.2457e-02, -5.2681e-03, -1.4819e-02, -1.1565e-02,\n",
      "         4.4582e-03,  1.2649e-02, -2.3415e-02,  1.8277e-02,  8.0764e-03,\n",
      "         2.3026e-03,  2.8628e-03, -5.5260e-03,  3.3074e-02, -2.9872e-04,\n",
      "         4.2635e-03, -1.4589e-03, -8.3786e-04,  2.0129e-02,  4.3251e-04,\n",
      "        -1.3979e-02, -1.1013e-02, -1.7868e-02, -9.1575e-03, -2.4409e-03])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print(\"fc1.bias.grad before backward\")\n",
    "print(net.fc1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"fc1.bias.grad before backward\")\n",
    "print(net.fc1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "for param in net.parameters():\n",
    "    param.data.sub_(param.grad.data *lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1261e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0804e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0351e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9900e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9456e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9015e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8578e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8144e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7715e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7291e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6869e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6451e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6039e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5628e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5223e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4820e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4421e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4026e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3635e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3247e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2863e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2482e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2104e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1730e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1360e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0992e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0629e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0268e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9912e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9556e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9206e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8858e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8514e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8173e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7834e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7499e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7168e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6837e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6512e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6189e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5869e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5552e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5237e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4927e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4616e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4311e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4008e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3708e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3410e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3115e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2822e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2533e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2246e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1961e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1680e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1399e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1123e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0849e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0577e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0307e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0040e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9776e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9514e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9254e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8997e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8741e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8488e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8238e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7990e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7743e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7500e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7257e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7018e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6780e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6546e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6312e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6081e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5853e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5625e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5401e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5178e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4957e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4739e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4521e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4306e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4093e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3882e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3673e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3466e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3260e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3057e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2854e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2655e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2456e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2260e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2066e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1872e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1681e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1491e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1304e-06, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 위와 같이 계산하기 힘드니, optimizer를 통해 적용\n",
    "\n",
    "# Create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "#In your training loop:\n",
    "num_epoch = 100\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()#grad 중첩 계산이 안 되게끔, 초기화\n",
    "    output = net(input)\n",
    "    loss = criterion(output, target) #criterion = nn.MSELoss() #mean squared loss\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()#params grad가 update 됨\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "195f7d4e7dfa36631d8b035cdcf7a97b6cf52e673cffc7538f8b1ac093d92219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
